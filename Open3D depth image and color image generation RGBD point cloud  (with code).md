#  First, the principle of the algorithm 

##  1. Implementation process 

   The RGB-D camera can measure the depth of each pixel. After measuring the depth, the RGB-D camera usually completes the pairing between the depth depth and the color map according to the placement of each camera during production, and outputs the one-to-one corresponding color map and depth map. We can read the color information and distance information at the same position, calculate the 3D camera coordinates of the pixels, and generate a point cloud. The calculation formula is: in the formula, it is the depth value, and the unit is meters; it is the scaling multiple of the depth value; it is the pixel coordinate, which is the 3D point cloud coordinate corresponding to the pixel; it is the focal length of the camera, and it is the optical center of the camera, which is the so-called internal parameter. The pose of the camera is also called the external parameter of the camera, which will change with the camera movement. Knowing the inner parameter can generate a point cloud from the color map and depth map, and knowing the outer parameter can splice the point cloud generated by the color map and depth map measured at different positions of the same object into a complete ground object point cloud. 

##  2. Main functions 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 Realize the fusion of color images and depth images into RGBD to generate point clouds. This function has 5 built-in parameters, which are: 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 This function is used to set the internal parameters of the camera and can be used as follows: 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 PinholeCameraIntrinsicParameters. PrimeSenseDefaul provides default camera parameters for Open3D. Its image resolution is: 640x480, focal length = (525.0, 525.0), optical center = (319.5, 239.5). The default external parameter is the identity matrix. 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 This function implements the internal parameter setting of the camera. 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 or 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 Note: The reason why the default outer parameter is reset to the above form is that the coordinates of the point cloud calculated in Open3D are all negative, see Equation 1; when using the identity matrix as the default outer parameter, the obtained point cloud is the opposite of the real scene. Multiplying the outer parameter set as above can remove the negative sign to make the point cloud consistent with the real scene. (As for why the above form? Try it yourself) 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
 This function converts an RGBD image into a point cloud. 

#  Code implementation 

##  1. Experimental data 

 ![avatar]( 839b3ff8779f467fad42ed6f1eaa96f9.png) 

   The test data in the code is one of the case data provided in the "Fourteen Lectures on Visual SLAM" widely circulated on the Internet. Color image, depth image  

##  2. Main parameters 

 The resolution of the image is: 640x480, that is: width = 640, height = 480. The internal parameters of the camera are:. The external parameters of the camera are: -0.228993 0.00645704 0.0287837 -0.0004327 -0.113131 -0.0326832 0.993042 The external parameters are expressed using quaternions, the first three are translation parameters, and the last four are quaternion coefficients. 

##  3. Complete code 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309574461462
  ```  
#  III. Display of results 

 ![avatar]( 9a58d0f421c94eb3a54037829c41069a.png) 

 1. Color image and depth image 2. Generated color point cloud 3. Generated colorless (intensity) point cloud  

#  IV. Relevant links 

 [1] 世界坐标系,相机坐标系和图像坐标系的转换(Python) [2] Open3D从RGB图与depth图产生RGB-D点云（采坑记录） [3] Open3d学习计划——6（RGBD图像） [4] Open3D 四元数、欧拉角、旋转向量转旋转矩阵 [5] Open3D 点云变换 

